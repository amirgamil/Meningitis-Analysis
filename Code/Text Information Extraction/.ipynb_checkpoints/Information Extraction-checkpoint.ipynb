{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import normaltest\n",
    "import random\n",
    "import copy\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building a BERT/Longformer classification pipeline where we feed in the summary and do a multilabel classification to predict the state in each country, I realized that this may not be the best way to tackle the problem for the following reasons\n",
    "1. Assuming [CLS] token encompasses all possible knowledge about every available country mentioned in the paragrah - this is unlikely especially when we use Longformer and the model is quite long\n",
    "2. The signal to noise ratio is very low (seems to be a common theme with this data)\n",
    "3. While BERT/Longformers are very good at extract feature representation from text, our end text algorithm will be much more effective if we can help it out a little bit\n",
    "\n",
    "\n",
    "Big Picture ideas:\n",
    "- Want to find a way to do a semantic search and segment information as it relates to different countries/noun mentioned in the report. Given a sentence like \"Burkina Faso....... Benin reached...\" want to be able to extract the relevant mentions - this includes determining the extent of the outbreak and potentially grabbing or localizing any specific regions mentioned in the text\n",
    "- Once we can segment the sentences, we can build something that uses BERT to extract feature representations which can be used for classification, NER, or something else. For now we are going to use this nltk pipeline to extract some basic information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_data = pd.read_csv(\"../../Current_Data/Month_data.csv\", usecols=[\"Country\", \"Date\", \"Cases\", \"Deaths\", \n",
    "                                                                       \"Summary\", \"Bordering Countries\"])\n",
    "month_data = month_data.drop(columns=[\"Bordering Countries\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
