{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "Wi_ZpTQMDNDY",
    "outputId": "2791c3a1-b4d0-443f-da9c-0e12b4565535"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-3736ded9-8824-4625-8385-510d1c575bf5\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-3736ded9-8824-4625-8385-510d1c575bf5\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving multilabel_classification to multilabel_classification\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from simpletransformers.classification import ClassificationModel\n",
    "# from simpletransformers.classification import MultiLabelClassificationModel\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
    "import ast\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "EX0XdLB0HtUo",
    "outputId": "aa2fefbe-d9f9-47bd-d4d6-b933f399ca48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The districts of Guidan-Roumji in Niger and Do...</td>\n",
       "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The week 6 was marked by a sudden apparition o...</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spatial analysis shows an epidemic area common...</td>\n",
       "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>During week 14 it is noted that: Burkina Faso:...</td>\n",
       "      <td>[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Burkina Faso: Titao was the last district in a...</td>\n",
       "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                                             labels\n",
       "0  The districts of Guidan-Roumji in Niger and Do...  [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. ...\n",
       "1  The week 6 was marked by a sudden apparition o...  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. ...\n",
       "2  Spatial analysis shows an epidemic area common...  [0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. ...\n",
       "3  During week 14 it is noted that: Burkina Faso:...  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. ...\n",
       "4  Burkina Faso: Titao was the last district in a...  [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. ..."
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_classification = pd.read_csv(\"/content/multilabel_classification\", usecols=[\"text\", \"labels\"])\n",
    "multi_label_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7WTddJYDNDc"
   },
   "outputs": [],
   "source": [
    "# summary_state = summary_state.drop(columns=[\"State\", \"Count\"])\n",
    "# summary_state = summary_state.rename(columns={\"Summary\":\"text\", \"Label\":\"labels\"})\n",
    "# summary_state = summary_state.reset_index(drop=True)\n",
    "multi_label_classification = multi_label_classification.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "NCKtwpGdDNDg",
    "outputId": "8e037e7c-761b-454a-bdc1-b6e7a296bd55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The districts of Guidan-Roumji in Niger and Do...</td>\n",
       "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The week 6 was marked by a sudden apparition o...</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Spatial analysis shows an epidemic area common...</td>\n",
       "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>During week 14 it is noted that: Burkina Faso:...</td>\n",
       "      <td>[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Burkina Faso: Titao was the last district in a...</td>\n",
       "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>123</td>\n",
       "      <td>From week 40 to 43 (corresponding to October 2...</td>\n",
       "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>From week 44 to 47 (corresponding to November ...</td>\n",
       "      <td>[0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>From week 48 to 52 (corresponding to December ...</td>\n",
       "      <td>[0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>The first week of the year 2017 is marked by t...</td>\n",
       "      <td>[0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>At week 6 of 2017, five districts reached the ...</td>\n",
       "      <td>[0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  ...                                             labels\n",
       "0        0  ...  [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. ...\n",
       "1        1  ...  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. ...\n",
       "2        2  ...  [0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. ...\n",
       "3        3  ...  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. ...\n",
       "4        4  ...  [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. ...\n",
       "..     ...  ...                                                ...\n",
       "123    123  ...  [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. ...\n",
       "124    124  ...  [0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. ...\n",
       "125    125  ...  [0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. ...\n",
       "126    126  ...  [0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. ...\n",
       "127    127  ...  [0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. ...\n",
       "\n",
       "[128 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separation = int(0.8 * len(multi_label_classification))\n",
    "train_data = multi_label_classification[:separation]\n",
    "test_data = multi_label_classification[separation:]\n",
    "print(len(test_data))\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "9vkBXS-RILIq",
    "outputId": "aee05b88-3ac5-47e1-b390-4a6ab4ce732d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-q5ekn_ge\n",
      "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-q5ekn_ge\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (1.18.4)\n",
      "Collecting tokenizers==0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 9.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (20.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2019.12.20)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 59.8MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 58.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.7)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0) (1.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2.9)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (0.15.1)\n",
      "Building wheels for collected packages: transformers, sacremoses\n",
      "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-2.11.0-cp36-none-any.whl size=675468 sha256=aeb1cd44ef5a543c49fb98327479ebdc190afec9cd815bcc4480d0adb8b2917d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ogt9ccn_/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=865307bef273c52a47672ba5a6219adb64f02b0e32b7a45928d4033308a55a8d\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built transformers sacremoses\n",
      "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dKt_FUNclxax",
    "outputId": "3ddc236f-e0ad-47b2-9738-e4e1acbd3971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: run_language_modeling.py [-h] [--model_name_or_path MODEL_NAME_OR_PATH]\r\n",
      "                                [--model_type MODEL_TYPE]\r\n",
      "                                [--config_name CONFIG_NAME]\r\n",
      "                                [--tokenizer_name TOKENIZER_NAME]\r\n",
      "                                [--cache_dir CACHE_DIR]\r\n",
      "                                [--train_data_file TRAIN_DATA_FILE]\r\n",
      "                                [--eval_data_file EVAL_DATA_FILE]\r\n",
      "                                [--line_by_line] [--mlm]\r\n",
      "                                [--mlm_probability MLM_PROBABILITY]\r\n",
      "                                [--block_size BLOCK_SIZE] [--overwrite_cache]\r\n",
      "                                --output_dir OUTPUT_DIR\r\n",
      "                                [--overwrite_output_dir] [--do_train]\r\n",
      "                                [--do_eval] [--do_predict]\r\n",
      "                                [--evaluate_during_training]\r\n",
      "                                [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\r\n",
      "                                [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\r\n",
      "                                [--per_gpu_train_batch_size PER_GPU_TRAIN_BATCH_SIZE]\r\n",
      "                                [--per_gpu_eval_batch_size PER_GPU_EVAL_BATCH_SIZE]\r\n",
      "                                [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\r\n",
      "                                [--learning_rate LEARNING_RATE]\r\n",
      "                                [--weight_decay WEIGHT_DECAY]\r\n",
      "                                [--adam_epsilon ADAM_EPSILON]\r\n",
      "                                [--max_grad_norm MAX_GRAD_NORM]\r\n",
      "                                [--num_train_epochs NUM_TRAIN_EPOCHS]\r\n",
      "                                [--max_steps MAX_STEPS]\r\n",
      "                                [--warmup_steps WARMUP_STEPS]\r\n",
      "                                [--logging_dir LOGGING_DIR]\r\n",
      "                                [--logging_first_step]\r\n",
      "                                [--logging_steps LOGGING_STEPS]\r\n",
      "                                [--save_steps SAVE_STEPS]\r\n",
      "                                [--save_total_limit SAVE_TOTAL_LIMIT]\r\n",
      "                                [--no_cuda] [--seed SEED] [--fp16]\r\n",
      "                                [--fp16_opt_level FP16_OPT_LEVEL]\r\n",
      "                                [--local_rank LOCAL_RANK]\r\n",
      "                                [--tpu_num_cores TPU_NUM_CORES]\r\n",
      "                                [--tpu_metrics_debug]\r\n",
      "run_language_modeling.py: error: argument --no_cuda: ignored explicit argument 'True'\r\n"
     ]
    }
   ],
   "source": [
    "#This code does language modeling as the first initial step of fine-tuning on a cusotm WHO report of meningitis\n",
    "#This is so the the model can learn some of the domain specific knowledge necessary to understand some of the indivial countries' reports\n",
    "!python3 \"run_language_modeling.py\"  \\\n",
    "    --output_dir=output \\\n",
    "    --model_type=longformer \\\n",
    "    --model_name_or_path=\"allenai/longformer-base-4096\" \\\n",
    "    --per_device_train_batch_size=1\\\n",
    "    --do_train \\\n",
    "    --train_data_file=\"finetune.txt\" \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qahkWrJgCmGn"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "from transformers import LongformerModel, LongformerTokenizer, LongformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dYHlVKPVDNDz",
    "outputId": "64162db8-58bd-41fd-96d2-091b87068605",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): LongformerSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = LongformerTokenizer.from_pretrained('/content/output')\n",
    "model = LongformerModel.from_pretrained('/content/output')\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IEATROmBDND1",
    "outputId": "f868be24-3553-4688-b66f-121c94306e80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Hello, my dog is cute</s>\n",
      "<s>\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#note when encoded the start of every token is added with an <s> for classification purposes\n",
    "input_ids = tokenizer.encode(\"Hello, my dog is cute\")  # Batch size 1\n",
    "print(tokenizer.decode(input_ids))\n",
    "print(tokenizer.decode(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4r7ydk0DDND4",
    "outputId": "7c1b1cf1-57d0-4216-cc49-63299120bf34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2530\n"
     ]
    }
   ],
   "source": [
    "tokenized = multi_label_classification[\"text\"]\\\n",
    "                                    .apply(lambda x: tokenizer.encode(x, add_special_tokens_tokens=True))\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "print(max_len)\n",
    "#padded according to max_length so we can feed the model in batches - padding works as such, add 0s after the length\n",
    "#of the original sequence l such that the new length is = max_len = 2530\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "S-nkKjOTDND7",
    "outputId": "6dc7cf72-5a11-4873-ee9c-5d660ec4288b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1 1 ... 0 0 2]\n",
      " [2 1 1 ... 0 0 2]\n",
      " [2 1 1 ... 0 0 2]\n",
      " ...\n",
      " [2 1 1 ... 0 0 2]\n",
      " [2 1 1 ... 0 0 2]\n",
      " [2 1 1 ... 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "np.array(padded.shape)\n",
    "#Add masking so that know BERT knows where to attend to => so it can ignore padding\n",
    "#adds a 1 everwhere where the condition of padded != 0 is satisfied, in other words everywhere there isn't padding\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "#add global attention represented with 2 - for now just add 1 at the classification <s> token\n",
    "attention_mask[:, [0, -1]] = 2\n",
    "print(attention_mask)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "input_ids = torch.tensor(padded).to(device)\n",
    "attention_mask = torch.tensor(attention_mask).to(device)\n",
    "\n",
    "def create_save_feature_representation():\n",
    "  first_time = True\n",
    "  for i in range(0,len(input_ids),2):\n",
    "    with torch.no_grad():\n",
    "      predictions, hidden_states = model(input_ids[i:i+2], attention_mask=attention_mask[i:i+2])\n",
    "      scores = predictions[:,0,:].cpu().numpy()\n",
    "      if not first_time:\n",
    "        curr = np.load(\"lang_features.npy\")\n",
    "        scores = np.concatenate((curr, scores))\n",
    "      else:\n",
    "        first_time = False\n",
    "      np.save(\"lang_features.npy\",scores)\n",
    "\n",
    "create_save_feature_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fp5EXbTWtVjV"
   },
   "outputs": [],
   "source": [
    "features = np.load(\"lang_features.npy\")\n",
    "#convert the labels into numpy arrays since they are stored as string representations\n",
    "multi_label_classification[\"labels\"] = multi_label_classification[\"labels\"].apply(lambda x: np.fromstring(x[1:-1], dtype=np.float32, sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JzUWtG7bDND-",
    "outputId": "f20ba645-19b4-4748-b7a0-e190b07dda9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, test_features = features[:separation], features[separation:]\n",
    "hidden_size = features.shape[1]\n",
    "\n",
    "#convert to float datatype that can be then cast to a tensor in PyTorch\n",
    "labels = np.array([label for label in np.array(multi_label_classification[\"labels\"].values)])\n",
    "train_labels, test_labels = labels[:separation], labels[separation:]\n",
    "multi_label_classification.iloc[0][\"labels\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "p6KwwpHUDNEB",
    "outputId": "a4f391a6-0e2d-44c1-82a8-af079b27a5e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "Epoch 0 with training loss: 0.8406721353530884\n",
      "Epoch 1 with training loss: 0.8182004690170288\n",
      "Epoch 2 with training loss: 0.806324303150177\n",
      "Epoch 3 with training loss: 0.7982347011566162\n",
      "Epoch 4 with training loss: 0.7923925518989563\n",
      "Epoch 5 with training loss: 0.787848711013794\n",
      "Epoch 6 with training loss: 0.7841944098472595\n",
      "Epoch 7 with training loss: 0.7809910774230957\n",
      "Epoch 8 with training loss: 0.7782623171806335\n",
      "Epoch 9 with training loss: 0.7758951783180237\n",
      "Epoch 10 with training loss: 0.7737647294998169\n",
      "Epoch 11 with training loss: 0.7718138694763184\n",
      "Epoch 12 with training loss: 0.7699738144874573\n",
      "Epoch 13 with training loss: 0.7682682275772095\n",
      "Epoch 14 with training loss: 0.7667174339294434\n",
      "Epoch 15 with training loss: 0.7653347849845886\n",
      "Epoch 16 with training loss: 0.7640621662139893\n",
      "Epoch 17 with training loss: 0.7628525495529175\n",
      "Epoch 18 with training loss: 0.7617048025131226\n",
      "Epoch 19 with training loss: 0.7606009244918823\n",
      "Epoch 20 with training loss: 0.7595781087875366\n",
      "Epoch 21 with training loss: 0.758614182472229\n",
      "Epoch 22 with training loss: 0.7576924562454224\n",
      "Epoch 23 with training loss: 0.7568144202232361\n",
      "Epoch 24 with training loss: 0.7559844255447388\n",
      "Epoch 25 with training loss: 0.7552111744880676\n",
      "Epoch 26 with training loss: 0.7544623613357544\n",
      "Epoch 27 with training loss: 0.7537353038787842\n",
      "Epoch 28 with training loss: 0.7530378103256226\n",
      "Epoch 29 with training loss: 0.7523751258850098\n",
      "Epoch 30 with training loss: 0.7517316341400146\n",
      "Epoch 31 with training loss: 0.751114010810852\n",
      "Epoch 32 with training loss: 0.7505253553390503\n",
      "Epoch 33 with training loss: 0.74994295835495\n",
      "Epoch 34 with training loss: 0.7493867874145508\n",
      "Epoch 35 with training loss: 0.7488490343093872\n",
      "Epoch 36 with training loss: 0.7483305931091309\n",
      "Epoch 37 with training loss: 0.7478307485580444\n",
      "Epoch 38 with training loss: 0.747351348400116\n",
      "Epoch 39 with training loss: 0.746888279914856\n",
      "Epoch 40 with training loss: 0.7464302778244019\n",
      "Epoch 41 with training loss: 0.7459842562675476\n",
      "Epoch 42 with training loss: 0.7455499172210693\n",
      "Epoch 43 with training loss: 0.745112955570221\n",
      "Epoch 44 with training loss: 0.7446848154067993\n",
      "Epoch 45 with training loss: 0.7442704439163208\n",
      "Epoch 46 with training loss: 0.7438544034957886\n",
      "Epoch 47 with training loss: 0.7434556484222412\n",
      "Epoch 48 with training loss: 0.7430669069290161\n",
      "Epoch 49 with training loss: 0.7426843643188477\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.dtype)\n",
    "epochs = 50\n",
    "neural_network = nn.Sequential(\n",
    "                    nn.Linear(hidden_size, 1000),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(1000),\n",
    "                    nn.Linear(1000, 800),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(800),\n",
    "                    nn.Linear(800, 800),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(800),\n",
    "                    nn.Linear(800, 600),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(600),\n",
    "                    nn.Linear(600, 400),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(400),\n",
    "                    nn.Linear(400, 400),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(400),\n",
    "                    nn.Linear(400, 200),\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm1d(200),\n",
    "                    nn.Linear(200, 20),\n",
    "                    nn.Sigmoid(),\n",
    "                    )\n",
    "neural_network.cuda()\n",
    "dtype = torch.cuda.FloatTensor\n",
    "neural_network.type = torch.cuda.FloatTensor\n",
    "train_features, test_features = torch.tensor(train_features).to(device), torch.tensor(test_features).to(device)\n",
    "train_labels, test_labels = torch.tensor(train_labels).to(device), torch.tensor(test_labels).to(device)\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = optim.Adam(neural_network.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  optimizer.zero_grad()\n",
    "  output = neural_network(train_features)\n",
    "  loss = criterion(output, train_labels)\n",
    "  print(\"Epoch {0} with training loss: {1}\".format(epoch, loss))\n",
    "  loss.backward()\n",
    "  optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "wN-JtyBdvwpl",
    "outputId": "77012f23-2901-43c2-a6e3-4da606810f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.]\n",
      " [1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0.]\n",
      " [0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0.]\n",
      " [0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      " [0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0.]\n",
      " [0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      " [0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1.]]\n",
      "F1 Score:  0.5329052969502407\n",
      "ROC-AUC:  0.5662542161675027\n"
     ]
    }
   ],
   "source": [
    "def convert_to_thresholds(data):\n",
    "  return data>0.5\n",
    "\n",
    "def test_model():\n",
    "  preds = neural_network(test_features).cpu().data.numpy()\n",
    "  correct = test_labels.cpu().numpy()\n",
    "  print(correct)\n",
    "  preds = convert_to_thresholds(preds)\n",
    "  print(\"F1 Score: \", f1_score(preds, correct, average=\"micro\"))\n",
    "  print(\"ROC-AUC: \", roc_auc_score(correct, preds))\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qkq8OaYYBsu8"
   },
   "source": [
    "##Tests on simplified 2 state binary classification problem\n",
    "**Initial results tested with 20 labels:**\n",
    "F1 Score: 0.53\n",
    "ROC-AUC: 0.51\n",
    "\n",
    "**Tested on only the most present 8 labels** - as done with the forecasting pipeline (to check if this is a signal to noise ratio)\n",
    "F1 Score: 0.558\n",
    "ROC-AUC: 0.501\n",
    "\n",
    "So the issue here isn't due to noise - the Longformer is just not able to learn a meaningful enough feature representation that can map to the labels.\n",
    "\n",
    "Let's try to finetune our Longformer model first on some domain-specific text - reports from the WHO that outline how they plan to defeat Meningitis by 2030. After finetuning on this data, let's try to regenerate our feature representations of our report text and see if that changes our results with the multilabel classifier\n",
    "\n",
    "**After training a pre-trained model to do language modeling**\n",
    "F1 Score: 0.5329\n",
    "ROC-AUC: 0.566\n",
    "\n",
    "The results did improve but not significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2k9sE1KB7hw"
   },
   "outputs": [],
   "source": [
    "#As input to finetune model - need to tokenize and feed in sentences into longformer\n",
    "#In order to feed text into the longformer - need to pass in 3 things:\n",
    "#1. input_ids which are the tokenized sentences (with the correct tags e.g. <s>)\n",
    "#2. input_masks telling model where to pay attention to - i.e. where to ignore padding etc.\n",
    "#3. token type ids which tell models about relationship of different sentences (e.g. relevant to question and answering datasets) \n",
    "# since our input consists of single sentences, we don't need it however\n",
    "\n",
    "def tokenize_sentences(sentences):\n",
    "  input_ids, attention_masks = [], []\n",
    "  for sentence in sentences:\n",
    "    #encodings is a dictionary with the encoded sequence and additional information like the attention mask\n",
    "    encoded_dict = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=4096, pad_to_max_length=True, return_attention_mask=True)\n",
    "    input_ids.append(encoded_dict[\"input_ids\"])\n",
    "    attention_masks.append(encoded_dict[\"attention_mask\"])\n",
    "  return input_ids, attention_masks\n",
    "\n",
    "with open(\"finetune.txt\", \"r\") as f:\n",
    "  corpus = f.read().strip()\n",
    "  corpus = corpus.replace('.\"', '\".')\n",
    "  #split the corpus into an array of sentences - each sentence will be its own item in the array\n",
    "  sentences = re.split(\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\", corpus)\n",
    "  sep = int(0.8*len(sentences))\n",
    "  #save the last 20% of the data for test\n",
    "  train_dataset, test_dataset = sentences[:sep], sentences[sep:]\n",
    "\n",
    "input_ids, attention_masks = tokenize_sentences(train_dataset)\n",
    "print(len(input_ids)*4096)\n",
    "\n",
    "train_dataset, test_dataset = map(tokenize_sentences, train_sentences), map(tokenize_sentences, test_sentences)\n",
    "print(train_dataset)\n",
    "\n",
    "# config = LongformerConfig(dropout=0.2, attention_dropout=0.2)\n",
    "# config.output_hidden_states = False\n",
    "#note we're gonna be using the Longformer model we defined above so we don't need to define a new model here\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Simple Transformer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
