{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Simple Transformer.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzVnJXrLDNDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85385ad5-2c58-4d8d-dfcf-748882b9fde9"
      },
      "source": [
        "%run data_preprocessing.ipynb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:File `'data_preprocessing.ipynb.py'` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi_ZpTQMDNDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# from simpletransformers.classification import ClassificationModel\n",
        "# from simpletransformers.classification import MultiLabelClassificationModel\n",
        "import pandas as pd\n",
        "import logging\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
        "import ast\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX0XdLB0HtUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8bab4cac-ae5d-4aab-8aa1-7f4aac310189"
      },
      "source": [
        "multi_label_classification = pd.read_csv(\"/content/multilabel_classification\", usecols=[\"text\", \"labels\"])\n",
        "multi_label_classification.head()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The districts of Guidan-Roumji in Niger and Do...</td>\n",
              "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The week 6 was marked by a sudden apparition o...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Spatial analysis shows an epidemic area common...</td>\n",
              "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>During week 14 it is noted that: Burkina Faso:...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Burkina Faso: Titao was the last district in a...</td>\n",
              "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                             labels\n",
              "0  The districts of Guidan-Roumji in Niger and Do...  [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. ...\n",
              "1  The week 6 was marked by a sudden apparition o...  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. ...\n",
              "2  Spatial analysis shows an epidemic area common...  [0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. ...\n",
              "3  During week 14 it is noted that: Burkina Faso:...  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. ...\n",
              "4  Burkina Faso: Titao was the last district in a...  [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7WTddJYDNDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summary_state = summary_state.drop(columns=[\"State\", \"Count\"])\n",
        "# summary_state = summary_state.rename(columns={\"Summary\":\"text\", \"Label\":\"labels\"})\n",
        "# summary_state = summary_state.reset_index(drop=True)\n",
        "multi_label_classification = multi_label_classification.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCKtwpGdDNDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "68352782-3fb0-45c3-d757-bf1f837e7d3d"
      },
      "source": [
        "separation = int(0.8 * len(multi_label_classification))\n",
        "train_data = multi_label_classification[:separation]\n",
        "test_data = multi_label_classification[separation:]\n",
        "print(len(test_data))\n",
        "train_data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The districts of Guidan-Roumji in Niger and Do...</td>\n",
              "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>The week 6 was marked by a sudden apparition o...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Spatial analysis shows an epidemic area common...</td>\n",
              "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>During week 14 it is noted that: Burkina Faso:...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Burkina Faso: Titao was the last district in a...</td>\n",
              "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>123</td>\n",
              "      <td>From week 40 to 43 (corresponding to October 2...</td>\n",
              "      <td>[0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>124</td>\n",
              "      <td>From week 44 to 47 (corresponding to November ...</td>\n",
              "      <td>[0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>125</td>\n",
              "      <td>From week 48 to 52 (corresponding to December ...</td>\n",
              "      <td>[0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>126</td>\n",
              "      <td>The first week of the year 2017 is marked by t...</td>\n",
              "      <td>[0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>127</td>\n",
              "      <td>At week 6 of 2017, five districts reached the ...</td>\n",
              "      <td>[0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>128 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index  ...                                             labels\n",
              "0        0  ...  [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. ...\n",
              "1        1  ...  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. ...\n",
              "2        2  ...  [0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. ...\n",
              "3        3  ...  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. ...\n",
              "4        4  ...  [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. ...\n",
              "..     ...  ...                                                ...\n",
              "123    123  ...  [0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. ...\n",
              "124    124  ...  [0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. ...\n",
              "125    125  ...  [0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. ...\n",
              "126    126  ...  [0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. ...\n",
              "127    127  ...  [0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. ...\n",
              "\n",
              "[128 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wRSQ_7kDNDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhQhGmaiDNDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = ClassificationModel('roberta', 'roberta-base', num_labels=3, \n",
        "#                             use_cuda=False, args={\"train_batch_size\": 1 ,\n",
        "#                                                   'reprocess_input_data': True, 'overwrite_output_dir': True})\n",
        "\n",
        "model = MultiLabelClassificationModel('roberta', 'roberta-base', use_cuda=False, \n",
        "                                      num_labels=20, args={'reprocess_input_data': True,\n",
        "                                                           'overwrite_output_dir': True, 'num_train_epochs': 3})\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXxbZ2dCDNDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.train_model(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYVf08krDNDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#micro average takes into account true positives, false negatives, and false positives\n",
        "def f1_multiclass(labels, preds):\n",
        "    print(labels)\n",
        "    preds = preds>0.2\n",
        "    print(preds)\n",
        "    return f1_score(labels, preds, average='micro')\n",
        "\n",
        "result, model_outputs, wrong_predictions = model.eval_model(test_data, f1=f1_multiclass,\n",
        "                                                           roc=roc_auc_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTmbuHI9DNDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RThhUz6YDNDy",
        "colab_type": "text"
      },
      "source": [
        "The model achieves 87.5% accuracy with multiclass classification - for each report, sum the total number of states (0 1 or 2) and divide by the number of countries for which data is recorded.\n",
        "\n",
        "For multilabel classification (with random truncation)- (predicting the state of every country from the text):\n",
        "1. We will use the ROC-AUC evaluation metric which tells us for each label how good the model is at discriminating between classes (i.e. how good is it at predicting 0s as 0s and 1s as 1s)\n",
        "F1 = 0.702\n",
        "ROC = 0.5487\n",
        "\n",
        "Testing multilabel classification with a sliding window\n",
        "\n",
        "The results seem to be significantly worse for multilabel classification. My hypothesis for this is since BERT has a maximum number of tokens and much of the text is often larger than this limit, when it cuts out text to reduce it to the maximum size (i.e. by sampling from the middle) information is being lost which the model can't learn from. For example, if a part of the sentence cut out is one that talks about how bad the epidemic was in Burkina Faso, the model will assume a state of 0.\n",
        "\n",
        "Solution: LongFormer\n",
        "\n",
        "Model\n",
        "\n",
        "LongFormer -> Multilabel Classification (using either scikit-learn's multioutput classifier and fitting a logistic algorithm to each label or a simple affine layer with a sigmoid activation function)]\n",
        "\n",
        "\n",
        "*NOTE - in the future install transformers by running pip install git+https://github.com/huggingface/transformers in venv - i.e. installing directly from github and not from the latest release* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vkBXS-RILIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "b2c90369-9973-40d7-ac70-2c787601effe"
      },
      "source": [
        "pip install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-qjj7hoec\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-qjj7hoec\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (1.18.4)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 51.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==2.11.0) (0.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==2.11.0) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.11.0) (2.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.11.0) (0.15.1)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.11.0-cp36-none-any.whl size=666275 sha256=9803e96b4877bbb73f6327141510e744db26c5ba56bb472316e61d7289ad75bb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hh_v5xuu/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=718c924c13877ff2507561cd0a0f33a0e4330769e736bb498f7ae7d4f69539be\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dYHlVKPVDNDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfbeaa89-6a6d-436d-e3a5-ad7e49e6a297"
      },
      "source": [
        "from transformers import LongformerModel, LongformerTokenizer\n",
        "import numpy as np\n",
        "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "model = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
        "model.cuda()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LongformerModel(\n",
              "  (embeddings): RobertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "    (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
              "    (token_type_embeddings): Embedding(1, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): LongformerSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEATROmBDND1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "394f3a3c-8c53-4589-f3de-e2e7ea9c180e"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "#note when encoded the start of every token is added with an <s> for classification purposes\n",
        "input_ids = tokenizer.encode(\"Hello, my dog is cute\")  # Batch size 1\n",
        "print(tokenizer.decode(input_ids))\n",
        "print(tokenizer.decode(input_ids[0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jun  4 07:40:18 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    32W /  70W |   1515MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "<s> Hello, my dog is cute</s>\n",
            "<s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r7ydk0DDND4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26aa5113-1662-440c-dd02-39bcd483018e"
      },
      "source": [
        "tokenized = multi_label_classification[\"text\"]\\\n",
        "                                    .apply(lambda x: tokenizer.encode(x, add_special_tokens_tokens=True))\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "print(max_len)\n",
        "#padded according to max_length so we can feed the model in batches - padding works as such, add 0s after the length\n",
        "#of the original sequence l such that the new length is = max_len = 2530\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-nkKjOTDND7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9fd4dc75-f6ea-4686-db5a-126053b81ceb"
      },
      "source": [
        "np.array(padded.shape)\n",
        "#Add masking so that know BERT knows where to attend to => so it can ignore padding\n",
        "#adds a 1 everwhere where the condition of padded != 0 is satisfied, in other words everywhere there isn't padding\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "#add global attention represented with 2 - for now just add 1 at the classification <s> token\n",
        "attention_mask[:, [0, -1]] = 2\n",
        "print(attention_mask)\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "input_ids = torch.tensor(padded).to(device)\n",
        "attention_mask = torch.tensor(attention_mask).to(device)\n",
        "\n",
        "def create_save_feature_representation():\n",
        "  first_time = True\n",
        "  for i in range(0,len(input_ids),2):\n",
        "    with torch.no_grad():\n",
        "      predictions, hidden_states = model(input_ids[i:i+2], attention_mask=attention_mask[i:i+2])\n",
        "      scores = predictions[:,0,:].cpu().numpy()\n",
        "      if not first_time:\n",
        "        curr = np.load(\"lang_features.npy\")\n",
        "        scores = np.concatenate((curr, scores))\n",
        "      else:\n",
        "        first_time = False\n",
        "      np.save(\"lang_features.npy\",scores)\n",
        "\n",
        "create_save_feature_representation()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2 1 1 ... 0 0 2]\n",
            " [2 1 1 ... 0 0 2]\n",
            " [2 1 1 ... 0 0 2]\n",
            " ...\n",
            " [2 1 1 ... 0 0 2]\n",
            " [2 1 1 ... 0 0 2]\n",
            " [2 1 1 ... 0 0 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp5EXbTWtVjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = np.load(\"lang_features.npy\")\n",
        "#convert the labels into numpy arrays since they are stored as string representations\n",
        "multi_label_classification[\"labels\"] = multi_label_classification[\"labels\"].apply(lambda x: np.fromstring(x[1:-1], dtype=np.float32, sep=' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzUWtG7bDND-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features, test_features = features[:separation], features[separation:]\n",
        "hidden_size = features.shape[1]\n",
        "\n",
        "#convert to float datatype that can be then cast to a tensor in PyTorch\n",
        "labels = np.array([label for label in np.array(multi_label_classification[\"labels\"].values)])\n",
        "train_labels, test_labels = labels[:separation], labels[separation:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6KwwpHUDNEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "95446b43-ed55-4b6f-9086-411f542d400c"
      },
      "source": [
        "print(train_labels.dtype)\n",
        "epochs = 50\n",
        "logistic_model = nn.Sequential(\n",
        "                    nn.Linear(hidden_size, 20),\n",
        "                    nn.Sigmoid(),\n",
        "                    )\n",
        "logistic_model.cuda()\n",
        "dtype = torch.cuda.FloatTensor\n",
        "logistic_model.type = torch.cuda.FloatTensor\n",
        "train_features, test_features = torch.tensor(train_features).to(device), torch.tensor(test_features).to(device)\n",
        "train_labels, test_labels = torch.tensor(train_labels).to(device), torch.tensor(test_labels).to(device)\n",
        "criterion = nn.MultiLabelSoftMarginLoss()\n",
        "optimizer = optim.Adam(logistic_model.parameters(), lr=0.0001)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  optimizer.zero_grad()\n",
        "  output = logistic_model(train_features)\n",
        "  loss = criterion(output, train_labels)\n",
        "  print(\"Epoch {0} with training loss: {1}\".format(epoch, loss))\n",
        "  loss.backward()\n",
        "  optimizer.step()    "
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float32\n",
            "Epoch 0 with training loss: 0.8349576592445374\n",
            "Epoch 1 with training loss: 0.8344990015029907\n",
            "Epoch 2 with training loss: 0.834040641784668\n",
            "Epoch 3 with training loss: 0.8335826396942139\n",
            "Epoch 4 with training loss: 0.8331249356269836\n",
            "Epoch 5 with training loss: 0.8326676487922668\n",
            "Epoch 6 with training loss: 0.8322106599807739\n",
            "Epoch 7 with training loss: 0.8317540287971497\n",
            "Epoch 8 with training loss: 0.8312978744506836\n",
            "Epoch 9 with training loss: 0.8308420181274414\n",
            "Epoch 10 with training loss: 0.8303865790367126\n",
            "Epoch 11 with training loss: 0.8299315571784973\n",
            "Epoch 12 with training loss: 0.8294769525527954\n",
            "Epoch 13 with training loss: 0.8290228247642517\n",
            "Epoch 14 with training loss: 0.8285690546035767\n",
            "Epoch 15 with training loss: 0.8281158804893494\n",
            "Epoch 16 with training loss: 0.8276630640029907\n",
            "Epoch 17 with training loss: 0.8272107243537903\n",
            "Epoch 18 with training loss: 0.826758861541748\n",
            "Epoch 19 with training loss: 0.8263075351715088\n",
            "Epoch 20 with training loss: 0.8258567452430725\n",
            "Epoch 21 with training loss: 0.8254064321517944\n",
            "Epoch 22 with training loss: 0.8249565958976746\n",
            "Epoch 23 with training loss: 0.8245073556900024\n",
            "Epoch 24 with training loss: 0.8240585327148438\n",
            "Epoch 25 with training loss: 0.8236104249954224\n",
            "Epoch 26 with training loss: 0.8231627941131592\n",
            "Epoch 27 with training loss: 0.8227157592773438\n",
            "Epoch 28 with training loss: 0.8222692012786865\n",
            "Epoch 29 with training loss: 0.8218233585357666\n",
            "Epoch 30 with training loss: 0.8213781118392944\n",
            "Epoch 31 with training loss: 0.8209333419799805\n",
            "Epoch 32 with training loss: 0.8204892873764038\n",
            "Epoch 33 with training loss: 0.8200458288192749\n",
            "Epoch 34 with training loss: 0.8196030259132385\n",
            "Epoch 35 with training loss: 0.8191608190536499\n",
            "Epoch 36 with training loss: 0.8187192678451538\n",
            "Epoch 37 with training loss: 0.8182783722877502\n",
            "Epoch 38 with training loss: 0.8178381323814392\n",
            "Epoch 39 with training loss: 0.8173985481262207\n",
            "Epoch 40 with training loss: 0.8169596791267395\n",
            "Epoch 41 with training loss: 0.816521406173706\n",
            "Epoch 42 with training loss: 0.8160839080810547\n",
            "Epoch 43 with training loss: 0.8156470060348511\n",
            "Epoch 44 with training loss: 0.8152108788490295\n",
            "Epoch 45 with training loss: 0.8147754669189453\n",
            "Epoch 46 with training loss: 0.8143407106399536\n",
            "Epoch 47 with training loss: 0.8139066696166992\n",
            "Epoch 48 with training loss: 0.8134734630584717\n",
            "Epoch 49 with training loss: 0.8130408525466919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN-JtyBdvwpl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4e9ce9fa-ffe3-4a0b-9001-19b9be907711"
      },
      "source": [
        "def convert_to_thresholds(data):\n",
        "  return data>0.5\n",
        "\n",
        "def test_model():\n",
        "  preds = logistic_model(test_features).cpu().data.numpy()\n",
        "  correct = test_labels.cpu().numpy()\n",
        "  preds = convert_to_thresholds(preds)\n",
        "  print(\"F1 Score: \", f1_score(preds, correct, average=\"micro\"))\n",
        "  print(\"ROC-AUC: \", roc_auc_score(correct, preds))\n",
        "\n",
        "test_model()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score:  0.5273833671399594\n",
            "ROC-AUC:  0.4965403661137956\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}